{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer lifetime value in a discrete-time contractual setting\n",
    "*math and Python implementation*\n",
    "\n",
    "## Motivating question\n",
    "In a monthly/yearly (i.e., discrete-time) subscription business setting (i.e., contractual), based on our current customer‚Äôs characteristics, what is the expected value of a new customer?\n",
    "- Note that our setting is a discrete-time contractual setting. If your business model is not subscription based (i.e., non-contractual), please check out the [lifetimes](https://lifetimes.readthedocs.io/en/latest/?badge=latest) package in Python.\n",
    "\n",
    "## Assumptions \n",
    "- here we only focus on revenue and ignore the customer acquisition cost, and other costs.\n",
    "    \n",
    "    \n",
    "## Equation \n",
    "(Fader, Peter, & Bruce (2007a))\n",
    "\n",
    "The equation of the expected value of customer life time value is quite straightforward:\n",
    "\n",
    "- $E(CLV) = \\sum_{n=1}^{\\infty} m \\frac{s(t)}{(1+d)^t} $\n",
    "    \n",
    "- m: subscription rate\n",
    "\n",
    "- s(t): survival function at time t   \n",
    "\n",
    "- d: discount rate reflecting the time value of money\n",
    "    \n",
    "    \n",
    "\n",
    "## Example\n",
    "Here is an example from the paper Fader, Peter, & Bruce (2007b). Assume we have 1000 customers, at Year 1 (t0) we have all 1000 customers. At Year 2 (t1), only 631 customers are active. And at Year 5, only 326 customers are still active. Assume our subscription rate is $100/year and the discount rate is 10%.\n",
    "\n",
    "- m = $100/year\n",
    "- d = 10% \n",
    "\n",
    "| ID   | Year 1 | Year 2 | Year 3 | Year 4 | Year 5 |\n",
    "|------|--------|--------|--------|--------|--------|\n",
    "| 1    | 1      | 1      | 0      | 0      | 0      |\n",
    "| 2    | 1      | 0      | 0      | 0      | 0      |\n",
    "| 3    | 1      | 1      | 1      | 0      | 0      |\n",
    "| ...  |        |        |        |        |        |\n",
    "| 1000 | 1      | 0      | 0      | 0      | 0      |\n",
    "|      | 1000   | 631    | 468    | 382    | 326    |\n",
    "\n",
    "\n",
    "$ E(CLV) = 100 + 100\\frac{0.631}{1.1} + 100\\frac{0.468}{1.1^2} + 100\\frac{0.382}{1.1^3} + 100\\frac{0.326}{1.1^4} + 100\\frac{s(5)}{1.1^5} + ... 100\\frac{s(n)}{1.1^n} $\n",
    "\n",
    "- Based on the CLV equation, we can fill in the data and rewrite the equation as shown above.\n",
    "- Issue: the only issue is we do not know future survival rate. Thus, we can use the Geometric-beta model to model our data and predict the survival function.    \n",
    "    \n",
    "## Geometric-beta model\n",
    "(Fader, Peter, & Bruce (2007a))    \n",
    "\n",
    "### customer duration ~ geometric($\\theta$)     \n",
    "We assume that customer duration/lifetime follows a geometric distribution because customers can only churn once.\n",
    "\n",
    "- probability of churn: $\\theta$\n",
    "\n",
    "- probability of retention: $1-\\theta$\n",
    "\n",
    "- probability of customer churn at time t: P(T=t|$\\theta$) = $\\theta(1-\\theta)^{t-1}$    \n",
    "\n",
    "- survival rate at time t: $S(t|\\theta) = (1-\\theta)^t$\n",
    "\n",
    "- retention rate at time t: $r(t) = \\frac{s(t)}{s(t-1)}$\n",
    "\n",
    "### $\\theta \\sim beta(\\alpha, \\beta)$\n",
    "We model the heterogeneity of ùúÉ as a beta distribution. We use beta distribution because it is bounded by the interval [0, 1], and it comes in all possible shapes.\n",
    "\n",
    "- defined on the interval [0, 1] \n",
    "\n",
    "- $f(\\theta|\\alpha, \\beta) = \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)}$, $\\alpha, \\beta > 0$\n",
    "\n",
    "### Geometric-beta distribution    \n",
    "Then we can combine the geometric distribution and the beta distribution and calculate the joint distribution. And through some calculation of Beta functions and Gamma functions, we can calculate the probability of customer churn at any time t and also the retention rate at any time t.\n",
    "\n",
    "- $p(T=t|\\alpha, \\beta) = \\int_{0}^{1}p(T=t|\\theta)f(\\theta|\\alpha, \\beta)d\\theta$   \n",
    "\n",
    "    - $p(T=1|\\alpha, \\beta) = \\frac{B(\\alpha+1, \\beta)}{B(\\alpha, \\beta)} = \\frac{\\Gamma(\\alpha+1)\\Gamma(\\beta)\\Gamma(\\alpha+\\beta)}{\\Gamma(\\alpha +\\beta+1)\\Gamma(\\alpha)\\Gamma(\\beta)} = \\frac {\\alpha}{\\alpha+\\beta}$  \n",
    "    - $p(T=t|\\alpha, \\beta) = \\frac{\\beta+t-2}{\\alpha+\\beta+t-1}p(T=t-1)$ for t>1   \n",
    "\n",
    "- $r(t) = \\frac{\\beta+t-1}{\\alpha+\\beta+t-1}$\n",
    "\n",
    "- Likelihood function: probability of losing $n_1$ customer at t1, losing $n_2$ customer at t2, ... and keep ${n-\\sum{n_t}}$ customer at the end of the observed period. \n",
    "$L(\\alpha, \\beta|data) = p(T=1|\\alpha,\\beta)^{n_1}p(T=2|\\alpha,\\beta)^{n_2} ...p(T=n-1|\\alpha,\\beta)^{n_{(n-1)}} s(T=t|\\alpha,\\beta)^{n-\\sum{n_t}}$   \n",
    "\n",
    "- Log-likelihood function: $LL(\\alpha, \\beta|data)= ln(L(\\alpha, \\beta|data))$\n",
    "\n",
    "### Find the maximum likelihood estimator for $\\alpha$ and $\\beta$\n",
    "\n",
    "- In order to find the maximum likelihood estimator for our parameters, we then maximize the log-likelihood function or minimize the negative log-likelihood function. Through optimization procedure, we get the MLE values for ùõº and ùõΩ.\n",
    "\n",
    "\n",
    "## Calculate CLV \n",
    "### Given $\\alpha$ and $\\beta$, calculate survival rate for each time point\n",
    "- $r(t) = \\frac{\\beta+t-1}{\\alpha+\\beta+t-1}$\n",
    "\n",
    "- $s(t) = 1$ when t = 0 \n",
    "\n",
    "- $s(t) = r(t)s(t-1)$ when t>0\n",
    "\n",
    "### calculate CLV \n",
    "choose a reasonable large number for k \n",
    "\n",
    "- $E(CLV) = \\sum_{n=1}^{k} m \\frac{s(t)}{(1+d)^t} $\n",
    "\n",
    "## Python implementation\n",
    "### Maximum likelihood estimation\n",
    "Here is my Python implementation for calculate the log likelihood function, and to optimize the negative log likelihood function. Note that we need to give the parameter an initial value as a starting point for optimization. In our example here, the initial values for ùõº and ùõΩ are both 1.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from autograd import value_and_grad, hessian\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "def _loglikelihood(params, n, active, return_s=False):\n",
    "    \"\"\"\n",
    "    params: alpha and beta initial values    \n",
    "    n: total number of people starting at t0\n",
    "    actives: # of people stayed active at each time point starting at t1\n",
    "    \"\"\"\n",
    "    t = list(range(1, len(active)+1))  # t: [ 1, 2, ...]\n",
    "    alpha, beta = params\n",
    "    p = []\n",
    "    s = []\n",
    "    lost = []\n",
    "    ll = []\n",
    "    for i in t:\n",
    "        if i == 1: \n",
    "            p.append(alpha/(alpha+beta))\n",
    "            s.append(1- p[0])\n",
    "            lost.append(n-active[0])\n",
    "        else: \n",
    "            p.append((beta+i-2)/(alpha+beta+i-1) * p[-1])\n",
    "            s.append(s[-1] - p[i-1])\n",
    "            lost.append(active[i-2] - active[i-1])\n",
    "            \n",
    "        ll.append(lost[i-1] * np.log(p[i-1]))\n",
    "        #print('p: ', p[i-1])\n",
    "    ll.append(active[-1] * np.log(s[-1]))\n",
    "    \n",
    "    #print('s: ', s[-1])\n",
    "    if return_s== True:\n",
    "        return s\n",
    "    else:\n",
    "        return ll \n",
    "    \n",
    "def _negative_log_likelihood(params, n, active):\n",
    "    return -(np.sum(_loglikelihood(params, n, active)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.array((1,1)) #init params\n",
    "n = 1000\n",
    "active = [631, 482, 382, 326]\n",
    "#active = [869, 743, 653, 593, 551, 517, 491]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_negative_log_likelihood(params, n, active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(\n",
    "        _negative_log_likelihood,\n",
    "        args = (n, active), #parameters we do not optimize on \n",
    "        tol=1e-13,\n",
    "        x0= np.array((1,1)), #starting value of params \n",
    "        bounds=[(0, None), (0, None)],\n",
    "        options={'ftol' : 1e-100000000},\n",
    "    )\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through optimization, the optimized negative log likelihood is 1409.5, and the MLE for ùõº and ùõΩ are 0.78 and 1.35.\n",
    "\n",
    "### Model fit\n",
    "\n",
    "Here is my function to access model fit. Here I am only comparing the observed and calculated survival rate. You can change this function to compare likelihood function and retention rate as well.\n",
    "The first plot here used the initial parameters (1,1) as the model parameter, we can see that the model calculated survival rate is not very ideal. The second plot used the MLE values for the parameters and the model calculated survival rate is very close to the observed survival rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_survival(params, n, active):\n",
    "    t = list(range(1, len(active)+1))\n",
    "    df_plot = pd.DataFrame({'t': t, \n",
    "                            'observed': [x/n for x in active], \n",
    "                            'model': _loglikelihood(params, n, active, return_s=True)})\n",
    "    return df_plot.hvplot('t',['observed', 'model'], title = 'Survival rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using init params (1,1)\n",
    "model_fit_survival(params, n, active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using optimized params res.x \n",
    "model_fit_survival(res.x, n, active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate CLV\n",
    "Now we can calculate the expected value of the customer lifetime value using the MLE parameters. We can see that the expected value of a new customer is $362.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_clv(alpha, beta, d, net_cf):\n",
    "    t = list(range(0, 200))\n",
    "    r = []\n",
    "    s = []\n",
    "    disc = []\n",
    "    for i in t:\n",
    "        if i == 0: \n",
    "            r.append(0)\n",
    "            s.append(1)\n",
    "            disc.append(1)\n",
    "        else:\n",
    "            r.append((beta+i-1)/(alpha+beta+i-1))\n",
    "            s.append(r[i]*s[i-1])\n",
    "            disc.append((1/(1+d)**i))\n",
    "    clv = net_cf * sum([x * y for x, y in zip(s, disc)])\n",
    "    return clv\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha, beta = res.x\n",
    "d = 0.1\n",
    "net_cf = 100\n",
    "e_clv(alpha, beta, d, net_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Sophia Yang on [August 24, 2020](https://towardsdatascience.com/customer-lifetime-value-in-a-discrete-time-contractual-setting-math-and-python-implementation-af3ef606cefe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
