{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for data scientists\n",
    "\n",
    "*Using pytest, ipytest, and hypothesis for unit testing*\n",
    "\n",
    "Software testing is essential for software development. It is recommended for software engineers to use test-driven development (TDD), which is a software development process that develops test cases first and then develops the software. For data scientists, it is not always easy and plausible to write tests first. Nevertheless, software testing is so important. Every data scientist should know how to do unit testing and use unit testing in their data science workflow. A lot of data scientists already use assertions, which is very important and a first step to test-driven development. This article will step up from assertations and focus on three tools -- `pytest`, `ipytest`, and `hypothesis`. There are other testing tools available, such as the Python built-in library `unittest`. `unittest` has similar functionalities as `pytest`, but I think `pytest` is more user friendly for data scientists and includes more useful features. \n",
    "\n",
    "## Set up\n",
    "To install `pytest` and `hypothesis`, run `conda install pytest hypothesis -c defaults -c conda-forge`.\n",
    "\n",
    "To use  `pytest` and `hypothesis`, we will need separate testing scripts. For simplicity, in our examples below, our main script for data accessing, processing, and modeling will be called `stock_example.py`. Our testing script will be called `test_stock_example.py`. In practice, data accessing, processing, and modeling are usually in separate files and there might be multiple testing files. It is recommended to save your test files under a `tests` directory. \n",
    "\n",
    "\n",
    "<pre>\n",
    ".\n",
    "&#8866; stock_exmple.py\n",
    "&#8866; tests\n",
    "        &#8985; test_stock_example.py\n",
    "</pre>\n",
    "\n",
    "\n",
    "## Test data accessing and the input data\n",
    "\n",
    "Data Scientists may get data from everywhere, from internal sources, vendors, and different APIs. Our data pipeline and model depends on successfully getting the right data. If we fail to get the data or if the vendor changes the data schema or format, we want to be able to catch these issues in a testing script. For example, if we are interested in looking at the stock market data. We can use the yahoo finance API (`pip install yfinance`). \n",
    "\n",
    "In `stock_example.py`, I wrote a function `stock_data` to get data from multiple stocks and return a pandas dataframe (see image below, left panel). To test this function, in the `test_stock_example.py` file (see image below, right panel), given two stocks and defined timeframe and when `stock_data` called, `df_func` is the dataframe we get from the function `stock_data`. `df_truth` is what we desire. Then `df_func` must be the same as the `df_truth`. `assert_frame_equal` is a good function to use when compare two dataframes. \n",
    "\n",
    "If your testing case is large and you do not want to check if the two dataframes are the same, you can use assertions in the testing script to check for dataframe shape, duplicates, column names, missing values, and others (e.g., `assert len(df_func) == 2`). \n",
    "\n",
    "\n",
    "\n",
    "![](testing1.png)\n",
    "\n",
    "Now if we run `pytest` or `python -m pytest` (if pytest does not add the current directory in the PYTHONPATH). Then \n",
    "we can see we pass the test. The dataframe we got from the function is indeed the dataframe we expect to see. This simple test will tell us if we have trouble accessing data through the API or if the data format changes. \n",
    "\n",
    "![](testing2.png) \n",
    "\n",
    "\n",
    "## Test plots\n",
    "\n",
    "Data scientists often produces visualization reports or dashboard and they may not want the visualization images to change by accident. `pytest-mpl` allows us to test if our images changes or not. First, we need to install `pytest-mpl`:\n",
    "\n",
    "```\n",
    "conda install pytest-mpl -c defaults -c conda-forge\n",
    "```\n",
    "\n",
    "Next, in our main file `stock_example.py` (see image below, left panel), we added a function `stock_plot`, which produces line plots for multiple stocks. In the testing file `test_stock_example.py` (see image below, right panel), we added a testing function `test_stock_plot` which calls and tests the `stock_plot` function. Note that we also added a decorator `@pytest.mark.mpl_image_compare(remove_text=True)` to indicate where we want to compare images. \n",
    "\n",
    "![](testing3.png) \n",
    "\n",
    "Before we run `pytest`, we need to run the following to generate a baseline image for future images to compare with. Images will be saved under the tests/baseline directory. \n",
    "\n",
    "```\n",
    "python -m pytest -k test_stock_example --mpl-generate-path=tests/baseline\n",
    "```\n",
    "\n",
    "Then we run `pytest` and compare new images with the baseline image:\n",
    "\n",
    "```\n",
    "pytest --mpl\n",
    "```\n",
    "\n",
    "![](testing4.png) \n",
    "\n",
    "\n",
    "## Test data processing \n",
    "\n",
    "\n",
    "parameterize \n",
    "fixture\n",
    "hypothesis (regular expression)\n",
    "\n",
    "\n",
    "test model accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as spo\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def get_data(tickers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    use yfinance to get stock \"Adj Close\" data\n",
    "    \"\"\"\n",
    "    return yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "\n",
    "def stock_plot(price):\n",
    "    fig, ax = plt.subplots()\n",
    "    tickers = price.columns.to_list()\n",
    "    for ticker in tickers:\n",
    "        ax.plot(price[[ticker]], label=ticker)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Adjusted closing price')\n",
    "    ax.legend()\n",
    "    return fig\n",
    "\n",
    "def calculate_daily_returns(allocation, price):\n",
    "    \"\"\"\n",
    "    Calculate daily return\n",
    "    allocation: allocation of the stocks in your portfolio\n",
    "    price: adj close price for the stocks\n",
    "    \"\"\"\n",
    "    start_val = 1 #how much money we have to start with\n",
    "    normed = price/price.iloc[0] #normalize prices\n",
    "    allocated = normed * allocation\n",
    "    position = allocated * start_val\n",
    "    portfolio = position.sum(axis=1)\n",
    "    daily_returns = (portfolio/portfolio.shift(1)) - 1\n",
    "    return daily_returns\n",
    "\n",
    "def sharpe_ratio(allocation, price):\n",
    "    \"\"\"\n",
    "    Calculate negative sharpe ratio\n",
    "    allocation: allocation of the stocks in your portfolio\n",
    "    price: adj close price for the stocks\n",
    "    \"\"\"\n",
    "    daily_returns = calculate_daily_returns(allocation, price)\n",
    "    sharpe_ratio = (daily_returns.mean()/daily_returns.std()) * (-1)\n",
    "    return sharpe_ratio\n",
    "\n",
    "def optimize_sharpe_ratio(price):    \n",
    "    \"\"\"\n",
    "    optimizes sharpe ratio for best allocations\n",
    "    \"\"\"\n",
    "    tickers = price.columns.to_list()\n",
    "    allocation = np.ones(len(tickers))/len(tickers)\n",
    "    bounds = [(0.0, 1.0) for i in range(len(tickers))]\n",
    "    constraints = (\n",
    "        { 'type': 'ineq', 'fun': lambda inputs: 1.0 - np.sum(inputs) },\n",
    "        { 'type': 'ineq', 'fun': lambda inputs:  np.sum(inputs)-1 })\n",
    "    result = spo.minimize(\n",
    "        sharpe_ratio, allocation, args=price, method='SLSQP',\n",
    "        options={'disp':True},bounds=bounds,constraints=constraints)\n",
    "    allocations = result.x\n",
    "    return allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_series_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  4 of 4 completed\n",
      "Index(['AAPL', 'AMZN', 'MSFT', 'NVDA'], dtype='object')\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -0.15828298868569474\n",
      "            Iterations: 7\n",
      "            Function evaluations: 35\n",
      "            Gradient evaluations: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6408362, 0.       , 0.3591638, 0.       ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers = ['AAPL','AMZN','MSFT','NVDA']  \n",
    "start_date = '2019-05-02'\n",
    "end_date = '2020-01-03'\n",
    "\n",
    "df = get_data(tickers, start_date, end_date)  \n",
    "print(df.columns)\n",
    "optimize_sharpe_ratio(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_almost_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -0.16656066501485198\n",
      "            Iterations: 6\n",
      "            Function evaluations: 24\n",
      "            Gradient evaluations: 6\n"
     ]
    }
   ],
   "source": [
    "assert_array_almost_equal(optimize_sharpe_ratio(df), [1,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Test data processing pipeline\n",
    "\n",
    "Test dataframes, shape, duplicates, NAs, formats, assumptions or statistical properties e.g., normality,  outliers, \n",
    "\n",
    "## Test model output\n",
    "\n",
    "\n",
    "\n",
    "## Other things to consider\n",
    "\n",
    "### coverage\n",
    "### pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
